{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Representing and minimizing rules\n",
    "\n",
    "Our rules are represented as positive monotone formulas in CNF. This is flexible enough for practical purposes, while still allowing us to define a normal form suitable for diffing, etc.\n",
    "\n",
    "A _clause_ is a set of literals, and a _formula_ a set of clauses. We sort each lexicographically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Clause(object):\n",
    "    def __init__(self, *args):\n",
    "        self.literals = set(args)\n",
    "        \n",
    "    def __str__(self):\n",
    "        return \", \".join(map(str, sorted(self.literals)))\n",
    "    \n",
    "    def _repr_pretty_(self, p, cycle):\n",
    "       p.text(str(self) if not cycle else '...')\n",
    "    \n",
    "    def __lt__(self, other):\n",
    "        return sorted(self.literals) < sorted(other.literals)\n",
    "        \n",
    "class Formula(object):\n",
    "    def __init__(self, *args):\n",
    "        self.clauses = set(args)\n",
    "        \n",
    "    def __str__(self):\n",
    "        return \" \".join(map(lambda x: \"({})\".format(x), sorted(self.clauses)))\n",
    "    \n",
    "    def _repr_pretty_(self, p, cycle):\n",
    "       p.text(str(self) if not cycle else '...')\n",
    "    \n",
    "def formula(*sets):\n",
    "    return Formula(*map(lambda s: Clause(*s), sets))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(a, ab, c) (a, b, c) (ab, e)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "formula({'a', 'b', 'c'}, {'ab', 'e'}, {'a', 'ab', 'c'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For any formula, we define a normal form which exists, is unique, and is equivalent to the original formula under the usual interpretation of boolean logic.\n",
    "\n",
    "Clauses are always normal, since all literals are positive. Formulas are normalized by removing any clause subsumed by any other. A clause $c$ is _subsumed_ by a clause $s$ if $s \\subseteq c$. This is the obvious $O(mn)$ algorithm. Our clauses are almost always of size 1, so this is just fine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def subsumes(c, d):\n",
    "    return c.literals.issubset(d.literals)\n",
    "\n",
    "def normalize(formula):\n",
    "    minimized = set()\n",
    "    for c in formula.clauses:\n",
    "        minimized = {s for s in minimized if not subsumes(c, s)}\n",
    "        if not any(subsumes(s, c) for s in minimized):\n",
    "            minimized.add(c)\n",
    "    return Formula(*minimized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(a) (a, b) (a, c, d) (b) (c, d)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "form = formula({'a', 'b'}, {'b'}, {'a'}, {'c', 'd'}, {'a', 'c', 'd'})\n",
    "form"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(a) (b) (c, d)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normalize(form)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Matching\n",
    "\n",
    "The problem of matching rules to contexts amounts to testing formulas against truth-value assignments. But there are a few particularities which apply to our setting...\n",
    "\n",
    " - we want to evaluate rules under partial assignments as well as total assignemnts, identifying\n",
    "   rules which are not yet satisfied, but remain satisfiable by future assignments.\n",
    " - we're always monotonically extending partial assignments and then re-evaluating, so it seems \n",
    "   like a good idea to re-use the current state as a starting point for future evaluations.\n",
    " - many assignments will co-exist at the same time, and each may subsequently be used as the\n",
    "   starting point for future evaluations.\n",
    "   \n",
    "If we use an algorithm that just freshly evaluates all the rules against each assignment from scratch, there's not much more to do. If, however, we want to use an algorithm that performs work incrementally from the prior assignment, then we also want persistent data structures so that the old and new states can co-exist without copying.\n",
    "\n",
    "Here are some ideas...\n",
    "\n",
    "#### Brute force\n",
    "\n",
    " 1. Index rules by properties set in that context\n",
    " 2. Do nothing else until a property is requested\n",
    " 3. Find all rules setting that property\n",
    " 4. Evaluate each rule against the current assignment\n",
    " 5. Apply specificity logic, etc.\n",
    " \n",
    "This might be just fine, particularly if there are lots of different properties with only a few settings each. For situations where lots of properties are queried and set in the same context, there are some simple tricks that could speed things up. For instance, a given rule could be marked as satisfied (or not) by a given assignment so that future properties queried in the same context wouldn't need to reevaluate those rules. But in the case where are many, many settings of the same property in a large number of different rules, this seems unavoidably pretty bad.\n",
    "\n",
    "There maybe other use cases for which this approach wouldn't work as well. For instance, enumerating properties set in a given context, or enumerating all the possible values of a given key that could be added to reveal additional settings. Those are more rare, though, and it would be ok if they were more expensive, as long as they're tractable.\n",
    "\n",
    "#### DAG/Rete\n",
    "\n",
    " 1. Use rules to build an immutable graph, with root nodes for each literal\n",
    " 2. As the context is extended with additional facts, propagate those facts through the graph,\n",
    "    activating child nodes as appropriate\n",
    " 3. When a node containing property settings is activated, add those settings to the properties\n",
    "    visible in the current context\n",
    " 4. Apply specificity logic, either separately or in step 3 when adding settings\n",
    " \n",
    "This is most similar to the current implementation, and most similar to what I've implemented so far for CCS2. Given the requirements above, the node activation state must be kept separately from the main graph, and in a persistent data structure. Likewise the visible settings.\n",
    "\n",
    "Querying properties and enumerating properties are both trivial. The problem of enumerating key values remains tricky, but I've already implemented one variant and it's not too bad.\n",
    "\n",
    "There are lots of variants of this involving different approaches to building the DAG. Since we're dealing with CNF terms, one possibility is to build a graph for disjunctions and one for conjunctions (or, equivalently, a single graph in two layers). The only thing remaining then is to optimize the structure of each of those graphs to amortize work done at each step.\n",
    "\n",
    "#### Other matching approaches\n",
    "\n",
    "There are other matching approaches to indexing and matching boolean formulas. Perhaps one of these would be better, but it would need to support partial matching (to find satisfiable but not yet satisfied rules), and may need to support an incremental implementation using immutable data structures, depending on its overall performance."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
